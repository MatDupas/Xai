\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ff_interpretability}
\citation{fair_washing}
\citation{please_stop}
\citation{membership_inference}
\citation{model_stealing}
\citation{guidotti2018survey}
\citation{lipton1}
\citation{molnar}
\citation{murdoch2019interpretable}
\citation{weller2017challenges}
\citation{been_kim1}
\citation{gilpin2018explaining}
\citation{keinan2004fair}
\citation{shapley}
\citation{shapley1988shapley}
\citation{kononenko2010efficient}
\citation{dt_surrogate2}
\citation{viper}
\citation{dt_surrogate1}
\citation{lime-sup}
\citation{lime}
\citation{wf_xnn}
\citation{ale_plot}
\citation{esl}
\citation{ice_plots}
\citation{friedler2019assessing}
\citation{molnar2019quantifying}
\citation{molnar2019quantifying}
\citation{slim}
\citation{wf_xnn}
\citation{sbrl}
\newlabel{fn:regs}{{2}{1}{}{Hfootnote.2}{}}
\newlabel{fn:Chen}{{5}{1}{}{Hfootnote.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Definitions and Examples}{1}{section.1}}
\newlabel{sec:intro}{{1}{1}{Definitions and Examples}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Interpretable and Explanation}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Explainable ML and Interpretable or White-box Models }{1}{subsection.1.2}}
\citation{feldman2015certifying}
\citation{hardt2016equality}
\citation{hcml}
\citation{uci}
\citation{gopinathan1998fraud}
\citation{fair_washing}
\citation{model_stealing}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Model Debugging and Fairness}{2}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Human-Centered ML}{2}{subsection.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Guidelines}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Guideline: Use Explanations to Enable Understanding, not Trust.}{2}{subsection.2.1}}
\newlabel{sec:trust}{{2.1}{2}{Guideline: Use Explanations to Enable Understanding, not Trust}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Guideline: Learn How Explainable ML is Used for Nefarious Purposes.}{2}{subsection.2.2}}
\newlabel{sec:nefarious}{{2.2}{2}{Guideline: Learn How Explainable ML is Used for Nefarious Purposes}{subsection.2.2}{}}
\citation{angwin16}
\citation{flores2016false}
\citation{dt_surrogate2}
\citation{viper}
\citation{dt_surrogate1}
\citation{lime-sup}
\citation{wf_xnn}
\citation{shapley}
\citation{kononenko2010efficient}
\citation{tree_shap}
\citation{ale_plot}
\citation{esl}
\citation{ice_plots}
\citation{art_and_sci}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:global_shap}{{1a}{3}{Consistent global Shapley feature importance values for $g_{\text {GBM}}$.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:global_shap}{{a}{3}{Consistent global Shapley feature importance values for $g_{\text {GBM}}$.\relax }{figure.caption.3}{}}
\newlabel{fig:resid}{{1b}{3}{$g_{\text {GBM}}$ deviance residuals and predictions by \texttt {PAY\_0}.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:resid}{{b}{3}{$g_{\text {GBM}}$ deviance residuals and predictions by \texttt {PAY\_0}.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An unconstrained GBM probability of default model, $g_{\text  {GBM}}$, generally over-emphasizes the importance of the input feature \texttt  {PAY\_0}, a customer's most recent repayment status. $g_{\text  {GBM}}$ produces large positive residuals when \texttt  {PAY\_0} indicates on-time payments (\texttt  {PAY\_0} $\leq $ 1) and large negative residuals when \texttt  {PAY\_0} indicates late payments (\texttt  {PAY\_0} $>$ 1). Combining explanatory and debugging techniques shows that $g_{\text  {GBM}}$ is explainable, but probably not trustworthy.\relax }}{3}{figure.caption.3}}
\newlabel{fig:global_shap_resid}{{1}{3}{An unconstrained GBM probability of default model, $g_{\text {GBM}}$, generally over-emphasizes the importance of the input feature \texttt {PAY\_0}, a customer's most recent repayment status. $g_{\text {GBM}}$ produces large positive residuals when \texttt {PAY\_0} indicates on-time payments (\texttt {PAY\_0} $\leq $ 1) and large negative residuals when \texttt {PAY\_0} indicates late payments (\texttt {PAY\_0} $>$ 1). Combining explanatory and debugging techniques shows that $g_{\text {GBM}}$ is explainable, but probably not trustworthy.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Guideline Corollary: Explainable ML Can be Used to Crack Nefarious Black-boxes.}{3}{subsubsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Augment Surrogate Models with Direct Explanations.}{3}{subsection.2.3}}
\newlabel{sec:surrogate}{{2.3}{3}{Augment Surrogate Models with Direct Explanations}{subsection.2.3}{}}
\newlabel{eq:f}{{1}{3}{Augment Surrogate Models with Direct Explanations}{equation.2.1}{}}
\citation{lime}
\citation{lime-sup}
\citation{wf_xnn}
\newlabel{fig:dt_surrogate}{{2a}{4}{Na\"ive $h_{\text {tree}}$, \textit {a surrogate model}, forms an approximate overall flowchart for the explained model, $g_{\text {GBM}}$.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:dt_surrogate}{{a}{4}{Na\"ive $h_{\text {tree}}$, \textit {a surrogate model}, forms an approximate overall flowchart for the explained model, $g_{\text {GBM}}$.\relax }{figure.caption.4}{}}
\newlabel{fig:pdp_ice}{{2b}{4}{Partial dependence and ICE curves generated \textit {directly from the explained model}, $g_{\text {GBM}}$.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:pdp_ice}{{b}{4}{Partial dependence and ICE curves generated \textit {directly from the explained model}, $g_{\text {GBM}}$.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces $h_{\text  {tree}}$ displays known interactions in $f = X_{\text  {num}1} * X_{\text  {num}4} + |X_{\text  {num}8}| * X_{\text  {num}9}^2$ for $\sim -0.923 < X_{\text  {num9}} < \sim 1.04$. Modeling of the known interaction between $X_{\text  {num9}}$ and $X_{\text  {num8}}$ in $f$ by $g_{\text  {GBM}}$ is confirmed by the divergence of partial dependence and ICE curves for $\sim -1 < X_{\text  {num9}} < \sim 1$. Explanations from a surrogate model have augmented and confirmed findings from a direct model visualization technique.\relax }}{4}{figure.caption.4}}
\newlabel{fig:pdp_ice_dt_surrogate}{{2}{4}{$h_{\text {tree}}$ displays known interactions in $f = X_{\text {num}1} * X_{\text {num}4} + |X_{\text {num}8}| * X_{\text {num}9}^2$ for $\sim -0.923 < X_{\text {num9}} < \sim 1.04$. Modeling of the known interaction between $X_{\text {num9}}$ and $X_{\text {num8}}$ in $f$ by $g_{\text {GBM}}$ is confirmed by the divergence of partial dependence and ICE curves for $\sim -1 < X_{\text {num9}} < \sim 1$. Explanations from a surrogate model have augmented and confirmed findings from a direct model visualization technique.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Guideline Corollary: Augment LIME with Direct Explanations.}{4}{subsubsection.2.3.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Coefficients for a local linear interpretable model, $h_{\text  {GLM}}$, with an intercept of 0.77 and an $R^2$ of 0.73. $h_{\text  {GLM}}$ is trained on a segment of the UCI credit card dataset containing higher-risk customers with late most recent repayment statuses, $\mathbf  {X}_{PAY \_ 0 > 1}$, and the predictions of a simple decision tree, $g_{\text  {tree}}(\mathbf  {X}_{\text  {PAY\_0} > 1})$.\relax }}{4}{table.caption.5}}
\newlabel{tab:lime}{{1}{4}{Coefficients for a local linear interpretable model, $h_{\text {GLM}}$, with an intercept of 0.77 and an $R^2$ of 0.73. $h_{\text {GLM}}$ is trained on a segment of the UCI credit card dataset containing higher-risk customers with late most recent repayment statuses, $\mathbf {X}_{PAY \_ 0 > 1}$, and the predictions of a simple decision tree, $g_{\text {tree}}(\mathbf {X}_{\text {PAY\_0} > 1})$.\relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Use Fully Transparent ML Mechanisms for Systems That Affect Humans.}{4}{subsection.2.4}}
\newlabel{sec:white_box}{{2.4}{4}{Use Fully Transparent ML Mechanisms for Systems That Affect Humans}{subsection.2.4}{}}
\citation{slim}
\citation{sbrl}
\citation{shapley}
\citation{lime}
\citation{lipovetsky2001analysis}
\citation{tree_shap}
\citation{shapley}
\citation{gosiewska2019safe}
\citation{feldman2015certifying}
\citation{hardt2016equality}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Guideline Corollary: Use Interpretable Models Along with Explanation Techniques.}{5}{figure.caption.6}}
\newlabel{fig:dt}{{3a}{5}{Simple decision tree, $g_{\text {tree}}$, trained on the UCI credit card data to predict default with validation AUC of 0.74. The decision policy for a high-risk individual is highlighted in red.\relax }{figure.caption.6}{}}
\newlabel{sub@fig:dt}{{a}{5}{Simple decision tree, $g_{\text {tree}}$, trained on the UCI credit card data to predict default with validation AUC of 0.74. The decision policy for a high-risk individual is highlighted in red.\relax }{figure.caption.6}{}}
\newlabel{fig:shap}{{3b}{5}{Locally-accurate Shapley contributions\\ for the highlighted individual's probability\\ of default.\relax }{figure.caption.6}{}}
\newlabel{sub@fig:shap}{{b}{5}{Locally-accurate Shapley contributions\\ for the highlighted individual's probability\\ of default.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A simple decision tree, $g_{\text  {tree}}$, is trained on the UCI credit card dataset to predict probability of default. $g_{\text  {tree}}$ has a validation AUC of 0.74. The decision-policy for a high-risk customer is highlighted in \ref  {fig:dt} and the locally-accurate Shapley contributions for this same individual's predicted probability are displayed in \ref  {fig:shap}. The Shapley values are helpful because they highlight the local importance of \texttt  {PAY\_2}, the individual's second most recent repayment status, which could be underestimated by examining the decision policy alone.\relax }}{5}{figure.caption.6}}
\newlabel{fig:dt_shap}{{3}{5}{A simple decision tree, $g_{\text {tree}}$, is trained on the UCI credit card dataset to predict probability of default. $g_{\text {tree}}$ has a validation AUC of 0.74. The decision-policy for a high-risk customer is highlighted in \ref {fig:dt} and the locally-accurate Shapley contributions for this same individual's predicted probability are displayed in \ref {fig:shap}. The Shapley values are helpful because they highlight the local importance of \texttt {PAY\_2}, the individual's second most recent repayment status, which could be underestimated by examining the decision policy alone.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Guideline Corollary: Use Explanations Along with Disparate Impact Analysis.}{5}{subsubsection.2.4.2}}
\bibstyle{ACM-Reference-Format}
\bibdata{responsible_xai}
\bibcite{fair_washing}{{1}{2019}{{A{\"\i }vodji et~al\unhbox \voidb@x \hbox {.}}}{{A{\"\i }vodji, Arai, Fortineau, Gambs, Hara, and Tapp}}}
\bibcite{angwin16}{{2}{2016}{{Angwin et~al\unhbox \voidb@x \hbox {.}}}{{Angwin, Larson, Mattu, and Kirchner}}}
\bibcite{ale_plot}{{3}{2016}{{Apley}}{{Apley}}}
\bibcite{dt_surrogate2}{{4}{2017}{{Bastani et~al\unhbox \voidb@x \hbox {.}}}{{Bastani, Kim, and Bastani}}}
\bibcite{viper}{{5}{2018}{{Bastani et~al\unhbox \voidb@x \hbox {.}}}{{Bastani, Pu, and Solar-Lezama}}}
\bibcite{dt_surrogate1}{{6}{1996}{{Craven and Shavlik}}{{Craven and Shavlik}}}
\bibcite{been_kim1}{{7}{2017}{{Doshi-Velez and Kim}}{{Doshi-Velez and Kim}}}
\bibcite{feldman2015certifying}{{8}{2015}{{Feldman et~al\unhbox \voidb@x \hbox {.}}}{{Feldman, Friedler, Moeller, Scheidegger, and Venkatasubramanian}}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Basic group disparity metrics across different marital statuses for monotonically constrained GBM model, $g_{\text  {mono}}$, trained on the UCI credit card dataset.\relax }}{6}{table.caption.7}}
\newlabel{tab:dia}{{2}{6}{Basic group disparity metrics across different marital statuses for monotonically constrained GBM model, $g_{\text {mono}}$, trained on the UCI credit card dataset.\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Conclusion}{6}{section.3}}
\newlabel{sec:conclusion}{{3}{6}{Conclusion}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A diagram of a proposed human-centered ML workflow in which explanations (highlighted in green) are used along with interpretable or white-box models, disparate impact analysis and remediation techniques, and other review and appeal mechanisms to create a fair, accountable, and transparent ML system.\relax }}{6}{figure.caption.8}}
\newlabel{fig:hc_ml}{{4}{6}{A diagram of a proposed human-centered ML workflow in which explanations (highlighted in green) are used along with interpretable or white-box models, disparate impact analysis and remediation techniques, and other review and appeal mechanisms to create a fair, accountable, and transparent ML system.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{References}{6}{section*.11}}
\bibcite{flores2016false}{{9}{2016}{{Flores et~al\unhbox \voidb@x \hbox {.}}}{{Flores, Bechtel, and Lowenkamp}}}
\bibcite{friedler2019assessing}{{10}{2019}{{Friedler et~al\unhbox \voidb@x \hbox {.}}}{{Friedler, Roy, Scheidegger, and Slack}}}
\bibcite{esl}{{11}{2001}{{Friedman et~al\unhbox \voidb@x \hbox {.}}}{{Friedman, Hastie, and Tibshirani}}}
\bibcite{hcml}{{12}{2016}{{Gillies et~al\unhbox \voidb@x \hbox {.}}}{{Gillies, Fiebrink, Tanaka, Garcia, Bevilacqua, Heloir, Nunnari, Mackay, Amershi, Lee, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{gilpin2018explaining}{{13}{2018}{{Gilpin et~al\unhbox \voidb@x \hbox {.}}}{{Gilpin, Bau, Yuan, Bajwa, Specter, and Kagal}}}
\bibcite{ice_plots}{{14}{2015}{{Goldstein et~al\unhbox \voidb@x \hbox {.}}}{{Goldstein, Kapelner, Bleich, and Pitkin}}}
\bibcite{gopinathan1998fraud}{{15}{1998}{{Gopinathan et~al\unhbox \voidb@x \hbox {.}}}{{Gopinathan, Biafore, Ferguson, Lazarus, Pathria, and Jost}}}
\bibcite{gosiewska2019safe}{{16}{2019}{{Gosiewska et~al\unhbox \voidb@x \hbox {.}}}{{Gosiewska, Gacek, Lubon, and Biecek}}}
\bibcite{guidotti2018survey}{{17}{2018}{{Guidotti et~al\unhbox \voidb@x \hbox {.}}}{{Guidotti, Monreale, Ruggieri, Turini, Giannotti, and Pedreschi}}}
\bibcite{art_and_sci}{{18}{2018}{{Hall}}{{Hall}}}
\bibcite{hardt2016equality}{{19}{2016}{{Hardt et~al\unhbox \voidb@x \hbox {.}}}{{Hardt, Price, Srebro, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{lime-sup}{{20}{2018}{{Hu et~al\unhbox \voidb@x \hbox {.}}}{{Hu, Chen, Nair, and Sudjianto}}}
\bibcite{keinan2004fair}{{21}{2004}{{Keinan et~al\unhbox \voidb@x \hbox {.}}}{{Keinan, Sandbank, Hilgetag, Meilijson, and Ruppin}}}
\bibcite{uci}{{22}{2013}{{Lichman}}{{Lichman}}}
\bibcite{lipovetsky2001analysis}{{23}{2001}{{Lipovetsky and Conklin}}{{Lipovetsky and Conklin}}}
\bibcite{lipton1}{{24}{2016}{{Lipton}}{{Lipton}}}
\bibcite{tree_shap}{{25}{2017}{{Lundberg et~al\unhbox \voidb@x \hbox {.}}}{{Lundberg, Erion, and Lee}}}
\bibcite{shapley}{{26}{2017}{{Lundberg and Lee}}{{Lundberg and Lee}}}
\bibcite{molnar}{{27}{2018}{{Molnar}}{{Molnar}}}
\bibcite{molnar2019quantifying}{{28}{2019}{{Molnar et~al\unhbox \voidb@x \hbox {.}}}{{Molnar, Casalicchio, and Bischl}}}
\bibcite{murdoch2019interpretable}{{29}{2019}{{Murdoch et~al\unhbox \voidb@x \hbox {.}}}{{Murdoch, Singh, Kumbier, Abbasi-Asl, and Yu}}}
\bibcite{lime}{{30}{2016}{{Ribeiro et~al\unhbox \voidb@x \hbox {.}}}{{Ribeiro, Singh, and Guestrin}}}
\bibcite{please_stop}{{31}{2018}{{Rudin}}{{Rudin}}}
\bibcite{shapley1988shapley}{{32}{1988}{{Shapley et~al\unhbox \voidb@x \hbox {.}}}{{Shapley, Roth, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{membership_inference}{{33}{2017}{{Shokri et~al\unhbox \voidb@x \hbox {.}}}{{Shokri, Stronati, Song, and Shmatikov}}}
\bibcite{kononenko2010efficient}{{34}{2010}{{Strumbelj and Kononenko}}{{Strumbelj and Kononenko}}}
\bibcite{model_stealing}{{35}{2016}{{Tram{\`e}r et~al\unhbox \voidb@x \hbox {.}}}{{Tram{\`e}r, Zhang, Juels, Reiter, and Ristenpart}}}
\bibcite{slim}{{36}{2016}{{Ustun and Rudin}}{{Ustun and Rudin}}}
\bibcite{wf_xnn}{{37}{2018}{{Vaughan et~al\unhbox \voidb@x \hbox {.}}}{{Vaughan, Sudjianto, Brahimi, Chen, and Nair}}}
\bibcite{weller2017challenges}{{38}{2017}{{Weller}}{{Weller}}}
\bibcite{ff_interpretability}{{39}{2017}{{Williams et~al\unhbox \voidb@x \hbox {.}}}{{Williams et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{sbrl}{{40}{2017}{{Yang et~al\unhbox \voidb@x \hbox {.}}}{{Yang, Rudin, and Seltzer}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{4.185pt}
\newlabel{tocindent2}{10.34999pt}
\newlabel{tocindent3}{18.198pt}
\newlabel{TotPages}{{7}{7}{}{page.7}{}}
